{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Neighbors Scalar Regression\n\nShows the usage of the nearest neighbors regressor with scalar response.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Pablo Marcos Manch\u00f3n\n# License: MIT\n\n# sphinx_gallery_thumbnail_number = 3\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV, KFold\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport skfda\nfrom skfda.ml.regression import KNeighborsRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this example, we are going to show the usage of the nearest neighbors\nregressors with scalar response. There is available a K-nn version,\n:class:`KNeighborsRegressor\n<skfda.ml.regression.KNeighborsRegressor>`, and other one based in the\nradius, :class:`RadiusNeighborsRegressor\n<skfda.ml.regression.RadiusNeighborsRegressor>`.\n\nFirstly we will fetch a dataset to show the basic usage.\n\nThe Canadian weather dataset contains the daily temperature and\nprecipitation at 35 different locations in Canada averaged over 1960 to\n1994.\n\nThe following figure shows the different temperature and precipitation\ncurves.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = skfda.datasets.fetch_weather()\nfd = data['data']\n\n\n# Split dataset, temperatures and curves of precipitation\nX, y_func = fd.coordinates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Temperatures\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Precipitation\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y_func.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will try to predict the total log precipitation, i.e,\n$logPrecTot_i = \\log \\sum_{t=0}^{365} prec_i(t)$ using the temperature\ncurves.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Sum directly from the data matrix\nprec = y_func.data_matrix.sum(axis=1)[:, 0]\nlog_prec = np.log(prec)\n\nprint(log_prec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As in the nearest neighbors classifier examples, we will split the dataset\nin two partitions, for training and test, using the sklearn function\n:func:`~sklearn.model_selection.train_test_split`.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, log_prec,\n                                                    random_state=7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Firstly we will try make a prediction with the default values of the\nestimator, using 5 neighbors and the $\\mathbb{L}^2$ distance.\n\nWe can fit the :class:`~skfda.ml.regression.KNeighborsRegressor` in the \nsame way than the\nsklearn estimators. This estimator is an extension of the sklearn\n:class:`~sklearn.neighbors.KNeighborsRegressor`, but accepting a\n:class:`~skfda.representation.grid.FDataGrid` as input instead of an array with\nmultivariate data.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "knn = KNeighborsRegressor(weights='distance')\nknn.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can predict values for the test partition using\n:meth:`~skfda.ml.regression.KNeighborsScalarRegressor.predict`.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pred = knn.predict(X_test)\nprint(pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following figure compares the real precipitations with the predicted\nvalues.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\nax = fig.add_subplot(1, 1, 1)\nax.scatter(y_test, pred)\nax.plot(y_test, y_test)\nax.set_xlabel(\"Total log precipitation\")\nax.set_ylabel(\"Prediction\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can quantify how much variability it is explained by the model with\nthe coefficient of determination $R^2$ of the prediction,\nusing :meth:`~skfda.ml.regression.KNeighborsScalarRegressor.score` for that.\n\nThe coefficient $R^2$ is defined as $(1 - u/v)$, where $u$\nis the residual sum of squares $\\sum_i (y_i - y_{pred_i})^ 2$\nand $v$ is the total sum of squares $\\sum_i (y_i - \\bar y )^2$.\n\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "score = knn.score(X_test, y_test)\nprint(score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this case, we obtain a really good aproximation with this naive approach,\nalthough, due to the small number of samples, the results will depend on\nhow the partition was done. In the above case, the explained variation is\ninflated for this reason.\n\nWe will perform cross-validation to test more robustly our model.\n\nAs in the neighbors classifiers examples, we can use a sklearn metric to\napproximate the $\\mathbb{L}^2$ metric between function, but with a\nmuch lower computational cost.\n\nAlso, we can make a grid search, using\n:class:`~sklearn.model_selection.GridSearchCV`, to determine the optimal\nnumber of neighbors and the best way to weight their votes.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "param_grid = {'n_neighbors': np.arange(1, 12, 2),\n              'weights': ['uniform', 'distance']}\n\n\nknn = KNeighborsRegressor(metric='euclidean', multivariate_metric=True)\ngscv = GridSearchCV(knn, param_grid, cv=KFold(n_splits=3,\n                                              shuffle=True, random_state=0))\ngscv.fit(X, log_prec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We obtain that 7 is the optimal number of neighbors.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Best params\", gscv.best_params_)\nprint(\"Best score\", gscv.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "More detailed information about the Canadian weather dataset can be obtained\nin the following references.\n\n * Ramsay, James O., and Silverman, Bernard W. (2006). Functional Data\n   Analysis, 2nd ed. , Springer, New York.\n\n *  Ramsay, James O., and Silverman, Bernard W. (2002). Applied Functional\n    Data Analysis, Springer, New York\\n'\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}